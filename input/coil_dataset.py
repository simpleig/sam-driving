import os
import glob
import traceback
import collections
import sys
import math
import copy
import json
import random
import numpy as np

import torch
import cv2
from PIL import Image

from torch.utils.data import Dataset

from . import splitter
from . import data_parser

# TODO: Warning, maybe this does not need to be included everywhere.
from configs import g_conf

from coilutils.general import sort_nicely

def parse_remove_configuration(configuration):
    """
    Turns the configuration line of sliptting into a name and a set of params.
    """

    if configuration is None:
        return "None", None
    print('conf', configuration)
    conf_dict = collections.OrderedDict(configuration)

    name = 'remove'
    for key in conf_dict.keys():
        if key != 'weights' and key != 'boost':
            name += '_'
            name += key

    return name, conf_dict


def get_episode_weather(episode):
    with open(os.path.join(episode, 'metadata.json')) as f:
        metadata = json.load(f)
    print(" WEATHER OF EPISODE ", metadata['weather'])
    return int(metadata['weather'])

class CoILDataset(Dataset):
    """ The conditional imitation learning dataset"""
    def __init__(self, root_dirs, transform=None, preload_names=None, train_dataset=False):
        # Setting the root directory for this dataset
        self.root_dirs = root_dirs
        self.train_dataset = train_dataset
        # We add to the preload name all the remove labels
        if g_conf.REMOVE is not None and g_conf.REMOVE is not "None":
            name, self._remove_params = parse_remove_configuration(g_conf.REMOVE)
            self.preload_names = [preload_name + '_' + name for preload_name in preload_names]
            self._check_remove_function = getattr(splitter, name)
        else:
            self._check_remove_function = lambda _, __: False
            self._remove_params = []
            self.preload_names = preload_names
        print("preload Name ", self.preload_names)

        self.sensor_data_names = []
        self.measurements = []
        self.from_which_dataset_list = []

        if g_conf.USE_REPRESENTATION_LOSS:
            self.perception_rep_datasets = None
            self.speed_rep_datasets = None
            self.intentions_rep_datasets = None
        
        for i in range(len(root_dirs)):
            # Load from already saved .npy file with filenames of sensor data and dataset of 
            # measurements; otherwise, generate this .npy file and get these filenames and measurements
            if self.preload_names is not None and \
                    os.path.exists(os.path.join('_preloads', self.preload_names[i] + '.npy')):
                print(" Loading from NPY %dth dataset" % (i + 1))
                sensor_data_names_dataset, measurements_dataset = np.load(
                    os.path.join('_preloads', self.preload_names[i] + '.npy'))
                print(sensor_data_names_dataset)
            else:
                sensor_data_names_dataset, measurements_dataset = self._pre_load_image_folders(root_dirs[i], i)

            self.sensor_data_names.extend(sensor_data_names_dataset)
            self.measurements.extend(measurements_dataset)
            self.from_which_dataset_list.extend([i] * len(measurements_dataset))
            
            if g_conf.USE_REPRESENTATION_LOSS:
                print(" Loading from NPY %dth representation dataset" % (i + 1))
                rep_dataset_name = os.path.basename(self.root_dirs[i])
                # Load pre-generated representations generated by squeeze network
                # rep datasets should be saved as np.float32 arrays to avoid copying when converting to torch.FloatTensors
                if g_conf.USE_PERCEPTION_REP_LOSS:
                    perception_rep_dataset = np.load(
                        os.path.join('_preloads', g_conf.EXPERT_EXP_FOLDER + '_' + g_conf.EXPERT_EXP + '_' + rep_dataset_name + '_perception_rep.npy'))
                if g_conf.USE_SPEED_REP_LOSS:
                    speed_rep_dataset = np.load(
                        os.path.join('_preloads', g_conf.EXPERT_EXP_FOLDER + '_' + g_conf.EXPERT_EXP + '_' + rep_dataset_name + '_speed_rep.npy'))
                if g_conf.USE_INTENTION_REP_LOSS:
                    intentions_rep_dataset = np.load(
                        os.path.join('_preloads', g_conf.EXPERT_EXP_FOLDER + '_' + g_conf.EXPERT_EXP + '_' + rep_dataset_name + '_intentions_rep.npy'))
                
                if g_conf.USE_PERCEPTION_REP_LOSS:
                    if self.perception_rep_datasets is None:
                        self.perception_rep_datasets = perception_rep_dataset
                    else:
                        self.perception_rep_datasets = np.concatenate((self.perception_rep_datasets, perception_rep_dataset), 0)
                if g_conf.USE_SPEED_REP_LOSS:
                    if self.speed_rep_datasets is None:
                        self.speed_rep_datasets = speed_rep_dataset
                    else:
                        self.speed_rep_datasets = np.concatenate((self.speed_rep_datasets, speed_rep_dataset), 0)
                if g_conf.USE_INTENTION_REP_LOSS:
                    if self.intentions_rep_datasets is None:
                        self.intentions_rep_datasets = intentions_rep_dataset
                    else:
                        self.intentions_rep_datasets = np.concatenate((self.intentions_rep_datasets, intentions_rep_dataset), 0)

        print("preload Names ", self.preload_names)

        self.transform = transform
        self.batch_read_number = 0

    def __len__(self):
        return len(self.measurements)

    def __getitem__(self, index):
        """
        Get item function used by the dataset loader
        returns all the measurements with the desired image.

        Args:
            index:

        Returns:

        """
        try:
            measurements = self.measurements[index].copy()
            # Make sure measurements values are FloatTensors
            for k, v in measurements.items():
                v = torch.from_numpy(np.asarray([v, ]))
                measurements[k] = v.float()
            
            for name, size in g_conf.SENSORS.items():
                if name == 'rgb':
                    # Read image from dataset, convert it to FloatTensor and normalize to [0, 1]
                    img_path = os.path.join(self.root_dirs[self.from_which_dataset_list[index]],
                                        self.sensor_data_names[index][0].split('/')[-2],
                                        self.sensor_data_names[index][0].split('/')[-1])
                    # Note that cv2 reads the image as BGR
                    img = cv2.imread(img_path, cv2.IMREAD_COLOR)
                    # Apply the image transformation
                    if self.transform is not None:
                        boost = 1
                        img = self.transform(self.batch_read_number * boost, img)
                    else:
                        img = img.transpose(2, 0, 1)
        
                    img = img.astype(np.float)
                    img = torch.from_numpy(img).type(torch.FloatTensor)
                    img = img / 255.
                    measurements['rgb'] = img
                elif name == 'seg':
                    # Read seg mask from dataset, remap classes, and then convert to one-hot encoded FloatTensor
                    img_path = os.path.join(self.root_dirs[self.from_which_dataset_list[index]],
                                        self.sensor_data_names[index][-1].split('/')[-2],
                                        self.sensor_data_names[index][-1].split('/')[-1])
                    seg = Image.open(img_path)
                    seg = np.asarray(seg)
                    # Remap classes
                    class_map = \
                        {0: 0, # None
                            1: 0, # Buildings -> None
                            2: 0, # Fences -> None
                            3: 0, # Other -> None
                            4: 1, # Pedestrians kept
                            5: 0, # Poles -> None
                            6: 2, # RoadLines kept
                            7: 3, # Roads kept
                            8: 2, # Sidewalks mapped to roadlines (both are boundaries of road)
                            9 : 0, # Vegetation -> None
                            10: 4, # Vehicles kept
                            11: 0, # Walls -> None
                            12: 5} # TrafficSigns kept (for traffic lights)
                    new_seg = np.zeros((seg.shape[0], seg.shape[1]))
                    for key, value in class_map.items():
                        new_seg[np.where(seg == key)] = value 
                    # One hot encode seg mask, for now hardcode max of class map values + 1
                    new_seg = np.eye(6)[new_seg.astype(np.int32)]
                    new_seg = new_seg.transpose(2, 0, 1)
                    new_seg = new_seg.astype(np.float)
                    new_seg = torch.from_numpy(new_seg).type(torch.FloatTensor)
                    measurements['seg'] = new_seg
            
            if g_conf.USE_REPRESENTATION_LOSS:
                # Get squeeze network's intermediate representations from loaded pre-saved dataset of them
                if g_conf.USE_PERCEPTION_REP_LOSS:
                    measurements['perception_rep'] = torch.as_tensor(self.perception_rep_datasets[index]).type(torch.FloatTensor)
                if g_conf.USE_SPEED_REP_LOSS:
                    measurements['speed_rep'] = torch.as_tensor(self.speed_rep_datasets[index]).type(torch.FloatTensor)
                if g_conf.USE_INTENTION_REP_LOSS:
                    measurements['intentions_rep'] = torch.as_tensor(self.intentions_rep_datasets[index]).type(torch.FloatTensor)
            self.batch_read_number += 1
        except AttributeError:
            print ("Blank IMAGE")

            measurements = self.measurements[0].copy()
            for k, v in measurements.items():
                v = torch.from_numpy(np.asarray([v, ]))
                measurements[k] = v.float()
            measurements['steer'] = 0.0
            measurements['throttle'] = 0.0
            measurements['brake'] = 0.0
            measurements['rgb'] = np.zeros(3, 88, 200)

        return measurements

    def is_measurement_partof_experiment(self, measurement_data):

        # If the measurement data is not removable is because it is part of this experiment dataa
        return not self._check_remove_function(measurement_data, self._remove_params)

    def _get_final_measurement(self, speed, measurement_data, angle,
                               directions, avaliable_measurements_dict):
        """
        Function to load the measurement with a certain angle and augmented direction.
        Also, it will choose if the brake is gona be present or if acceleration -1,1 is the default.

        Returns
            The final measurement dict
        """
        if angle != 0:
            measurement_augmented = self.augment_measurement(copy.copy(measurement_data), angle,
                                                             3.6 * speed,
                                                 steer_name=avaliable_measurements_dict['steer'])
        else:
            # We have to copy since it reference a file.
            measurement_augmented = copy.copy(measurement_data)

        if 'gameTimestamp' in measurement_augmented:
            time_stamp = measurement_augmented['gameTimestamp']
        else:
            time_stamp = measurement_augmented['elapsed_seconds']

        final_measurement = {}
        # We go for every available measurement, previously tested
        # and update for the measurements vec that is used on the training.
        for measurement, name_in_dataset in avaliable_measurements_dict.items():
            # This is mapping the name of measurement in the target dataset
            final_measurement.update({measurement: measurement_augmented[name_in_dataset]})

        # Add now the measurements that actually need some kind of processing
        final_measurement.update({'speed_module': speed / g_conf.SPEED_FACTOR})
        final_measurement.update({'directions': directions})
        final_measurement.update({'game_time': time_stamp})
        # Hack: use splitter's remove_angle function to exclude frames not coming from central camera
        final_measurement.update({'angle': angle})
        
        stop_traff_light = float(measurement_augmented['stop_traffic_lights'])
        stop_vehicle = float(measurement_augmented['stop_vehicle'])
        stop_pedestrian = float(measurement_augmented['stop_pedestrian'])
        final_measurement.update({'stop_traffic_lights': stop_traff_light})
        final_measurement.update({'stop_vehicle': stop_vehicle})
        final_measurement.update({'stop_pedestrian': stop_pedestrian})

        return final_measurement

    # 8/31/2019: add dataset_index argument so function knows which dataset is being preloaded
    def _pre_load_image_folders(self, path, dataset_index=0):
        """
        Pre load the image folders for each episode, keep in mind that we only take
        the measurements that we think that are interesting for now.

        Args
            the path for the dataset

        Returns
            sensor data names: it is a vector with n dimensions being one for each sensor modality
            for instance, rgb only dataset will have a single vector with all the image names.
            float_data: all the wanted float data is loaded inside a vector, that is a vector
            of dictionaries.

        """

        episodes_list = glob.glob(os.path.join(path, 'episode_*'))
        sort_nicely(episodes_list)
        # Do a check if the episodes list is empty
        if len(episodes_list) == 0:
            raise ValueError("There are no episodes on the training dataset folder %s" % path)

        sensor_data_names = []
        float_dicts = []

        number_of_hours_pre_loaded = 0

        # Now we do a check to try to find all the
        for episode in episodes_list:

            print('Episode ', episode)

            available_measurements_dict = data_parser.check_available_measurements(episode)

            if number_of_hours_pre_loaded > g_conf.NUMBER_OF_HOURS:
                # The number of wanted hours achieved
                break

            # Get all the measurements from this episode
            measurements_list = glob.glob(os.path.join(episode, 'measurement*'))
            sort_nicely(measurements_list)

            if len(measurements_list) == 0:
                print("EMPTY EPISODE")
                continue

            # A simple count to keep track how many measurements were added this episode.
            count_added_measurements = 0

            for measurement in measurements_list:

                data_point_number = measurement.split('_')[-1].split('.')[0]

                with open(measurement) as f:
                    measurement_data = json.load(f)

                # depending on the configuration file, we eliminated the kind of measurements
                # that are not going to be used for this experiment
                # We extract the interesting subset from the measurement dict

                speed = data_parser.get_speed(measurement_data)

                directions = measurement_data['directions']
                final_measurement = self._get_final_measurement(speed, measurement_data, 0,
                                                                directions,
                                                                available_measurements_dict)

                if self.is_measurement_partof_experiment(final_measurement):
                    sensor_data_names.append([])
                    float_dicts.append(final_measurement)
                    rgb = 'CentralRGB_' + data_point_number + '.png'
                    sensor_data_names[-1].append(os.path.join(episode.split('/')[-1], rgb))
                    seg = 'SemanticSeg_' + data_point_number + '.png'
                    sensor_data_names[-1].append(os.path.join(episode.split('/')[-1], seg))
                    count_added_measurements += 1

                # We do measurements for the left side camera
                # We convert the speed to KM/h for the augmentation

                # We extract the interesting subset from the measurement dict

                final_measurement = self._get_final_measurement(speed, measurement_data, -30.0,
                                                                directions,
                                                                available_measurements_dict)

                if self.is_measurement_partof_experiment(final_measurement):
                    sensor_data_names.append([])
                    float_dicts.append(final_measurement)
                    rgb = 'LeftRGB_' + data_point_number + '.png'
                    sensor_data_names[-1].append(os.path.join(episode.split('/')[-1], rgb))
                    count_added_measurements += 1

                # We do measurements augmentation for the right side cameras

                final_measurement = self._get_final_measurement(speed, measurement_data, 30.0,
                                                                directions,
                                                                available_measurements_dict)

                if self.is_measurement_partof_experiment(final_measurement):
                    sensor_data_names.append([])
                    float_dicts.append(final_measurement)
                    rgb = 'RightRGB_' + data_point_number + '.png'
                    sensor_data_names[-1].append(os.path.join(episode.split('/')[-1], rgb))
                    count_added_measurements += 1

            # Check how many hours were actually added
            last_data_point_number = measurements_list[-1].split('_')[-1].split('.')[0]
            number_of_hours_pre_loaded += (float(count_added_measurements / 10.0) / 3600.0)
            print(" Loaded ", number_of_hours_pre_loaded, " hours of data")


        # Make the path to save the pre loaded datasets
        if not os.path.exists('_preloads'):
            os.mkdir('_preloads')
        # If there is a name we saved the preloaded data
        if self.preload_names[dataset_index] is not None:
            np.save(os.path.join('_preloads', self.preload_names[dataset_index]), [sensor_data_names, float_dicts])

        return sensor_data_names, float_dicts

    def augment_directions(self, directions):

        if directions == 2.0:
            if random.randint(0, 100) < 20:
                directions = random.choice([3.0, 4.0, 5.0])

        return directions

    def augment_steering(self, camera_angle, steer, speed):
        """
            Apply the steering physical equation to augment for the lateral cameras steering
        Args:
            camera_angle: the angle of the camera
            steer: the central steering
            speed: the speed that the car is going

        Returns:
            the augmented steering

        """
        time_use = 1.0
        car_length = 6.0

        pos = camera_angle > 0.0
        neg = camera_angle <= 0.0
        # You should use the absolute value of speed
        speed = math.fabs(speed)
        rad_camera_angle = math.radians(math.fabs(camera_angle))
        val = g_conf.AUGMENT_LATERAL_STEERINGS * (
            math.atan((rad_camera_angle * car_length) / (time_use * speed + 0.05))) / 3.1415
        steer -= pos * min(val, 0.3)
        steer += neg * min(val, 0.3)

        steer = min(1.0, max(-1.0, steer))

        # print('Angle', camera_angle, ' Steer ', old_steer, ' speed ', speed, 'new steer', steer)
        return steer

    def augment_measurement(self, measurements, angle, speed, steer_name='steer'):
        """
            Augment the steering of a measurement dict

        """
        new_steer = self.augment_steering(angle, measurements[steer_name],
                                          speed)
        measurements[steer_name] = new_steer
        return measurements

    def controls_position(self):
        return np.where(self.meta_data[:, 0] == b'control')[0][0]


    """
        Methods to interact with the dataset attributes that are used for training.
    """

    def extract_targets(self, data):
        """
        Method used to get to know which positions from the dataset are the targets
        for this experiments
        Args:
            data: the set of all float data got from the dataset

        Returns:
            the float data that is actually targets

        Raises
            value error when the configuration set targets that didn't exist in metadata
        """
        targets_vec = []
        for target_name in g_conf.TARGETS:
            targets_vec.append(data[target_name])

        return torch.cat(targets_vec, 1)

    def extract_inputs(self, data):
        """
        Method used to get to know which positions from the dataset are the inputs
        for this experiments
        Args:
            data: the set of all float data got from the dataset

        Returns:
            the float data that is actually inputs

        Raises
            value error when the configuration set targets that didn't exist in metadata
        """
        inputs_vec = []
        for input_name in g_conf.INPUTS:
            inputs_vec.append(data[input_name])

        return torch.cat(inputs_vec, 1)

    def extract_intentions(self, data):
        """
        Method used to get to know which positions from the dataset are the stop intentions 
        for this experiments
        Args:
            data: the set of all float data got from the dataset

        Returns:
            the float data that is actually stop intentions

        Raises
            value error when the configuration set targets that didn't exist in metadata
        """
        inputs_vec = []
        for input_name in g_conf.INTENTIONS:
            inputs_vec.append(data[input_name])
        return torch.cat(inputs_vec, 1)
    
    def extract_representations(self, data):
        """
        Method used to get to know which positions from the dataset are the intermediate 
        representations for this experiments
        Args:
            data: the set of all float data got from the dataset

        Returns:
            the float data that is actually intermediate representations

        Raises
            value error when the configuration set targets that didn't exist in metadata
        """
        if g_conf.USE_PERCEPTION_REP_LOSS and g_conf.USE_INTENTION_REP_LOSS and g_conf.USE_SPEED_REP_LOSS:
            return [data['perception_rep'], data['speed_rep'], data['intentions_rep']]
        if g_conf.USE_PERCEPTION_REP_LOSS and g_conf.USE_SPEED_REP_LOSS:
            return [data['perception_rep'], data['speed_rep'], None]
        if g_conf.USE_INTENTION_REP_LOSS and g_conf.USE_SPEED_REP_LOSS:
            return [None, data['speed_rep'], data['intentions_rep']]
        if g_conf.USE_PERCEPTION_REP_LOSS and g_conf.USE_INTENTION_REP_LOSS:
            return [data['perception_rep'], None, data['intentions_rep']]
        if g_conf.USE_PERCEPTION_REP_LOSS:
            return [data['perception_rep'], None, None]
        if g_conf.USE_SPEED_REP_LOSS:
            return [None, data['speed_rep'], None]
        if g_conf.USE_INTENTION_REP_LOSS:
            return [None, None, data['intentions_rep']]
